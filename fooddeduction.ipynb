{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "a5e78ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb52c5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = r\"E:\\vishal teli\\FoodDeduction\\media\\Indian Food Images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bfebe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_dirs=[]\n",
    "food_name=[]\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        food_dirs.append(entry)\n",
    "        food_name.append(entry.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "f9caa9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_name_dict={}\n",
    "for i in range(len(food_name)):\n",
    "    food_name_dict[i]=food_name[i]\n",
    "with open(\"food_dist.dict\", 'wb') as file:\n",
    "    pickle.dump(food_name_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b4d84fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 80 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define data augmentation and normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Create image generator\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_to_data,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "len(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14935d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(80, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b69300cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 221s 2s/step - loss: 3.3545 - accuracy: 0.1918\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 216s 2s/step - loss: 3.0356 - accuracy: 0.2517\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 216s 2s/step - loss: 2.6887 - accuracy: 0.3410\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 215s 2s/step - loss: 2.3716 - accuracy: 0.4065\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 214s 2s/step - loss: 2.1561 - accuracy: 0.4543\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 216s 2s/step - loss: 1.9119 - accuracy: 0.5073\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 209s 2s/step - loss: 1.7583 - accuracy: 0.5533\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 212s 2s/step - loss: 1.4770 - accuracy: 0.6102\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 216s 2s/step - loss: 1.3556 - accuracy: 0.6467\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 256s 2s/step - loss: 1.1880 - accuracy: 0.6877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x203d7f8fed0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, epochs=10, steps_per_epoch=len(train_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aa62c0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_model.joblib']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib \n",
    "# Save the model as a pickle in a file \n",
    "joblib.dump(model, 'saved_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a109b40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "def predict_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "9f43f4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "calorie_mapping = {\n",
    "    0: 89,   # Example mapping for class 0\n",
    "    1: 60,   # Example mapping for class 1\n",
    "    2: 47,   # Example mapping for class 1\n",
    "    3: 50,   # Example mapping for class 1\n",
    "    4: 33,   # Example mapping for class 1\n",
    "    # Add mappings for other classes\n",
    "}\n",
    "\n",
    "def deduct_calories(predicted_class):\n",
    "    return calorie_mapping.get(predicted_class, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "de912e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model =model # Load or create your trained model\n",
    "\n",
    "# Define the function to predict and deduct calories\n",
    "def predict_and_deduct_calories(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Deduct calories based on the predicted class\n",
    "    calories_deducted = deduct_calories(predicted_class)\n",
    "\n",
    "    return predicted_class, calories_deducted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "71583e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    }
   ],
   "source": [
    "# Test the model with an example image\n",
    "image_path = 'Test image/adhirasam2.jpg'\n",
    "predicted_class,calores_deducted= predict_and_deduct_calories(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "0cd0cda7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d25c0836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calores_deducted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6140b64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(food_name)):\n",
    "    if i==predicted_class:\n",
    "        pred_food_name=food_name[i]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "0cd7008c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adhirasam'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_food_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8630e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=joblib.load('saved_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "bae6f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_deduct_calories(image_path):\n",
    "    # Load and preprocess the image\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "\n",
    "    # Make a prediction\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Deduct calories based on the predicted class\n",
    "    calories_deducted = deduct_calories(predicted_class)\n",
    "\n",
    "    return predicted_class, calories_deducted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "9f90574b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "image_path = 'Test image/poha2.jpg'\n",
    "predicted_class,calores_deducted= predict_and_deduct_calories(image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2f22ac89",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(food_name)):\n",
    "    if i==predicted_class:\n",
    "        pred_food_name=food_name[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "228b7043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poha'"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_food_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5701dd31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e80feb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "# Define paths\n",
    "path_to_data = \"Indian Food Images\"\n",
    "\n",
    "# Define data augmentation and normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Create image generator\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_to_data,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=20, steps_per_epoch=len(train_generator))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'saved_model.joblib')\n",
    "\n",
    "# Function to predict and deduct calories\n",
    "def predict_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return predicted_class\n",
    "\n",
    "calorie_mapping = {\n",
    "    0: 89,   # Example mapping for class 0\n",
    "    1: 60,   # Example mapping for class 1\n",
    "    2: 47,   # Example mapping for class 2\n",
    "    3: 50,   # Example mapping for class 3\n",
    "    4: 33,   # Example mapping for class 4\n",
    "    # Add mappings for other classes\n",
    "}\n",
    "\n",
    "def deduct_calories(predicted_class):\n",
    "    return calorie_mapping.get(predicted_class, 0)\n",
    "\n",
    "def predict_and_deduct_calories(image_path):\n",
    "    predicted_class = predict_image(image_path)\n",
    "    calories_deducted = deduct_calories(predicted_class)\n",
    "    return predicted_class, calories_deducted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aded5958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 80 classes.\n",
      "Epoch 1/2\n",
      "125/125 [==============================] - 431s 3s/step - loss: 4.6602 - accuracy: 0.0148\n",
      "Epoch 2/2\n",
      "125/125 [==============================] - 293s 2s/step - loss: 4.2625 - accuracy: 0.0282\n",
      "Model saved as food_classification_model.h5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Path to your dataset\n",
    "path_to_data = r\"E:\\vishal teli\\FoodDeduction\\media\\Indian Food Images\"\n",
    "food_dirs = []\n",
    "food_name = []\n",
    "\n",
    "# Load food directories and names\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        food_dirs.append(entry)\n",
    "        food_name.append(entry.name)\n",
    "\n",
    "# Creating dictionary for food names\n",
    "food_name_dict = {i: food_name[i] for i in range(len(food_name))}\n",
    "\n",
    "# Save the dictionary for future use\n",
    "with open(\"food_dist.dict\", 'wb') as file:\n",
    "    pickle.dump(food_name_dict, file)\n",
    "\n",
    "# Data augmentation and normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,        # Normalize pixel values between 0 and 1\n",
    "    shear_range=0.2,       # Random shear transformations\n",
    "    zoom_range=0.2,        # Random zoom\n",
    "    horizontal_flip=True   # Random horizontal flip\n",
    ")\n",
    "\n",
    "# Create image generator for training\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_to_data,\n",
    "    target_size=(224, 224),  # Resize images to 224x224\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Multi-class classification\n",
    ")\n",
    "\n",
    "# CNN model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the layers and add dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer - 80 classes (adjust this according to your dataset)\n",
    "model.add(Dense(80, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=2, steps_per_epoch=len(train_generator))\n",
    "\n",
    "# Save the model as an h5 file\n",
    "model.save('food_classification_model.h5')\n",
    "\n",
    "print(\"Model saved as food_classification_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3e0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model.joblib.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c67cb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import joblib\n",
    "\n",
    "# Define paths\n",
    "path_to_data = \"Indian Food Images\"\n",
    "\n",
    "# Define data augmentation and normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Create image generator\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_to_data,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Define the model architecture\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(train_generator.class_indices), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=20, steps_per_epoch=len(train_generator))\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'saved_model.joblib')\n",
    "\n",
    "# Function to predict and deduct calories\n",
    "def predict_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.0\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "    return predicted_class\n",
    "\n",
    "calorie_mapping = {\n",
    "    0: 89,   # Example mapping for class 0\n",
    "    1: 60,   # Example mapping for class 1\n",
    "    2: 47,   # Example mapping for class 2\n",
    "    3: 50,   # Example mapping for class 3\n",
    "    4: 33,   # Example mapping for class 4\n",
    "    # Add mappings for other classes\n",
    "}\n",
    "\n",
    "def deduct_calories(predicted_class):\n",
    "    return calorie_mapping.get(predicted_class, 0)\n",
    "\n",
    "def predict_and_deduct_calories(image_path):\n",
    "    predicted_class = predict_image(image_path)\n",
    "    calories_deducted = deduct_calories(predicted_class)\n",
    "    return predicted_class, calories_deducted\n",
    "\n",
    "\n",
    "    import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Path to your dataset\n",
    "path_to_data = r\"E:\\vishal teli\\FoodDeduction\\media\\Indian Food Images\"\n",
    "food_dirs = []\n",
    "food_name = []\n",
    "\n",
    "# Load food directories and names\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        food_dirs.append(entry)\n",
    "        food_name.append(entry.name)\n",
    "\n",
    "# Creating dictionary for food names\n",
    "food_name_dict = {i: food_name[i] for i in range(len(food_name))}\n",
    "\n",
    "# Save the dictionary for future use\n",
    "with open(\"food_dist.dict\", 'wb') as file:\n",
    "    pickle.dump(food_name_dict, file)\n",
    "\n",
    "# Data augmentation and normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,        # Normalize pixel values between 0 and 1\n",
    "    shear_range=0.2,       # Random shear transformations\n",
    "    zoom_range=0.2,        # Random zoom\n",
    "    horizontal_flip=True   # Random horizontal flip\n",
    ")\n",
    "\n",
    "# Create image generator for training\n",
    "batch_size = 32\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    path_to_data,\n",
    "    target_size=(224, 224),  # Resize images to 224x224\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  # Multi-class classification\n",
    ")\n",
    "\n",
    "# CNN model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the layers and add dense layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Output layer - 80 classes (adjust this according to your dataset)\n",
    "model.add(Dense(80, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_generator, epochs=2, steps_per_epoch=len(train_generator))\n",
    "\n",
    "# Save the model as an h5 file\n",
    "model.save('food_classification_model.h5')\n",
    "\n",
    "print(\"Model saved as food_classification_model.h5\")\n",
    "\n",
    "model.save('saved_model.joblib.joblib')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "195f7d4e7dfa36631d8b035cdcf7a97b6cf52e673cffc7538f8b1ac093d92219"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
